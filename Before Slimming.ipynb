{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'trial', 'pcm_RMSenergy_sma_amean',\n",
      "       'pcm_fftMag_mfcc_sma[1]_amean', 'pcm_fftMag_mfcc_sma[2]_amean',\n",
      "       'pcm_fftMag_mfcc_sma[3]_amean', 'pcm_fftMag_mfcc_sma[4]_amean',\n",
      "       'pcm_fftMag_mfcc_sma[5]_amean', 'pcm_fftMag_mfcc_sma[6]_amean',\n",
      "       'pcm_fftMag_mfcc_sma[7]_amean', 'pcm_fftMag_mfcc_sma[8]_amean',\n",
      "       'pcm_fftMag_mfcc_sma[9]_amean', 'pcm_fftMag_mfcc_sma[10]_amean',\n",
      "       'pcm_fftMag_mfcc_sma[11]_amean', 'pcm_fftMag_mfcc_sma[12]_amean',\n",
      "       'pcm_zcr_sma_amean', 'voiceProb_sma_amean', 'F0_sma_amean', '#pause',\n",
      "       'pause_frequency', 'pause_interval', 'mean', 'percent',\n",
      "       'jitterLocal_sma_amean', 'jitterDDP_sma_amean',\n",
      "       'shimmerLocal_sma_amean', 'EDA_PPT', 'HR_PPT', 'TEMP_PPT', 'BVP_PPT',\n",
      "       'ACC_PPT', 'IBI_PPT', 'EDA_FREQ_PPT', 'EDA_AMP_PPT',\n",
      "       'Brief fear of Negative Evaluation', 'CAI State Score',\n",
      "       'CAI Trait Full Score', 'STAI State Score',\n",
      "       'CAI Trait Public Speaking Score', 'STAI Trait Score',\n",
      "       'CAI Trait Dyadic Score', 'CAI Trait Small group Score', 'Age',\n",
      "       'Gender', 'Lang', 'college', 'presentation', 'ethnicity',\n",
      "       'presentation_3_months', 'highest_education'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "#############################\n",
    "# Import and combine all data\n",
    "#############################\n",
    "\n",
    "\n",
    "DATA_PATH = \"/Users/mvonebers/HUBBS-Lab/data/\"\n",
    "#DATA_PATH = \"/home/maggie/HUBBS-Lab/data/\"\n",
    "\n",
    "e4_data = pd.read_excel(DATA_PATH + \"E4_TEST.xlsx\")\n",
    "change_data = pd.read_excel(DATA_PATH + \"normalized_change.xlsx\")\n",
    "audio_data = pd.read_excel(DATA_PATH + \"audio_TEST.xlsx\")\n",
    "demo_data = pd.read_csv(DATA_PATH + \"Demographics Information.csv\")\n",
    "\n",
    "\n",
    "# Break apart the ID column into \"person\" and \"trial\"\n",
    "def clean_id(data):\n",
    "    data.insert(0, \"person\", [0] * data.shape[0])\n",
    "    data.insert(1, \"trial\", [0] * data.shape[0])\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        data.at[i, \"person\"] = int(data.at[i, \"id\"][7:])\n",
    "        data.at[i, \"trial\"] = int(data.at[i, \"id\"][5])\n",
    "    \n",
    "    data = data.drop(columns=['id'])\n",
    "    data = data.rename(columns={\"person\": \"id\"})\n",
    "    return data\n",
    "\n",
    "    \n",
    "e4_data = clean_id(e4_data)\n",
    "audio_data = clean_id(audio_data)    \n",
    "    \n",
    "all_data = pd.merge(e4_data, change_data, on='id')\n",
    "all_data = audio_data.merge(all_data, how='right')\n",
    "\n",
    "\n",
    "# Reorder survey data in order of most samples to least\n",
    "columns = all_data.columns.to_list()\n",
    "new_columns = deepcopy(columns)\n",
    "new_columns[35] = columns[40]\n",
    "new_columns[37] = columns[41] \n",
    "new_columns[38] = columns[37] \n",
    "new_columns[40] = columns[35]\n",
    "new_columns[41] = columns[38]\n",
    "\n",
    "all_data = all_data[new_columns]\n",
    "\n",
    "\n",
    "# what does this do?\n",
    "#demo_ids = demo_data['id'].to_list()\n",
    "#\n",
    "#for id_ in demo_ids:\n",
    "#    if id_ not in slope_ids:\n",
    "#        demo_data = demo_data[demo_data.id != id_]\n",
    "        \n",
    "all_data = all_data.merge(demo_data, how=\"right\")\n",
    "\n",
    "# The demographic data lists IDs that aren't present in the other data, so remove them\n",
    "all_data = all_data[all_data.id != 16]\n",
    "all_data = all_data[all_data.id != 27]\n",
    "all_data = all_data[all_data.id != 38]\n",
    "all_data = all_data[all_data.id != 43]\n",
    "all_data = all_data[all_data.id != 46]\n",
    "all_data = all_data[all_data.id != 49]\n",
    "all_data = all_data[all_data.id != 53]\n",
    "all_data = all_data[all_data.id != 58]\n",
    "all_data = all_data[all_data.id != 65]\n",
    "all_data = all_data[all_data.id != 66]\n",
    "\n",
    "#all_data\n",
    "print(all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pcm_RMSenergy_sma_amean</th>\n",
       "      <th>pcm_fftMag_mfcc_sma[1]_amean</th>\n",
       "      <th>pcm_fftMag_mfcc_sma[2]_amean</th>\n",
       "      <th>pcm_fftMag_mfcc_sma[3]_amean</th>\n",
       "      <th>pcm_fftMag_mfcc_sma[4]_amean</th>\n",
       "      <th>pcm_fftMag_mfcc_sma[5]_amean</th>\n",
       "      <th>pcm_fftMag_mfcc_sma[6]_amean</th>\n",
       "      <th>pcm_fftMag_mfcc_sma[7]_amean</th>\n",
       "      <th>pcm_fftMag_mfcc_sma[8]_amean</th>\n",
       "      <th>...</th>\n",
       "      <th>CAI Trait Dyadic Score</th>\n",
       "      <th>CAI Trait Small group Score</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Lang</th>\n",
       "      <th>college</th>\n",
       "      <th>presentation</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>presentation_3_months</th>\n",
       "      <th>highest_education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>-1.188091</td>\n",
       "      <td>1.458396</td>\n",
       "      <td>-0.644212</td>\n",
       "      <td>-0.697069</td>\n",
       "      <td>-0.543809</td>\n",
       "      <td>2.068849</td>\n",
       "      <td>-1.118681</td>\n",
       "      <td>0.597193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.004605</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>0.041306</td>\n",
       "      <td>0.371020</td>\n",
       "      <td>1.856301</td>\n",
       "      <td>-2.347585</td>\n",
       "      <td>2.857080</td>\n",
       "      <td>-0.310527</td>\n",
       "      <td>-0.021322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>-0.545172</td>\n",
       "      <td>-0.233862</td>\n",
       "      <td>0.693634</td>\n",
       "      <td>-1.303848</td>\n",
       "      <td>-0.635333</td>\n",
       "      <td>0.913341</td>\n",
       "      <td>-0.946743</td>\n",
       "      <td>-0.024012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.003113</td>\n",
       "      <td>0.120467</td>\n",
       "      <td>-0.326470</td>\n",
       "      <td>0.884765</td>\n",
       "      <td>-0.090467</td>\n",
       "      <td>0.182058</td>\n",
       "      <td>-0.183817</td>\n",
       "      <td>0.728905</td>\n",
       "      <td>-0.347066</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>-0.201158</td>\n",
       "      <td>-0.268297</td>\n",
       "      <td>0.201903</td>\n",
       "      <td>-0.366338</td>\n",
       "      <td>0.377646</td>\n",
       "      <td>0.226589</td>\n",
       "      <td>-0.530547</td>\n",
       "      <td>0.462883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-0.002165</td>\n",
       "      <td>-0.024271</td>\n",
       "      <td>0.128524</td>\n",
       "      <td>0.470709</td>\n",
       "      <td>1.293796</td>\n",
       "      <td>-1.696811</td>\n",
       "      <td>3.038422</td>\n",
       "      <td>-0.332586</td>\n",
       "      <td>-0.556816</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.058824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.001112</td>\n",
       "      <td>0.432318</td>\n",
       "      <td>-0.105907</td>\n",
       "      <td>1.495445</td>\n",
       "      <td>-1.006755</td>\n",
       "      <td>1.001877</td>\n",
       "      <td>0.911382</td>\n",
       "      <td>-0.181762</td>\n",
       "      <td>-0.036236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-0.003161</td>\n",
       "      <td>0.366671</td>\n",
       "      <td>0.193564</td>\n",
       "      <td>-0.023716</td>\n",
       "      <td>0.258827</td>\n",
       "      <td>0.975375</td>\n",
       "      <td>-0.922304</td>\n",
       "      <td>0.307595</td>\n",
       "      <td>-0.030484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-0.000485</td>\n",
       "      <td>0.394130</td>\n",
       "      <td>0.261597</td>\n",
       "      <td>-0.139036</td>\n",
       "      <td>0.246072</td>\n",
       "      <td>0.183514</td>\n",
       "      <td>0.162386</td>\n",
       "      <td>-0.175606</td>\n",
       "      <td>-0.127135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>-0.020902</td>\n",
       "      <td>0.018043</td>\n",
       "      <td>0.745624</td>\n",
       "      <td>0.887429</td>\n",
       "      <td>-3.439343</td>\n",
       "      <td>1.431305</td>\n",
       "      <td>-0.421041</td>\n",
       "      <td>-1.802264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.030377</td>\n",
       "      <td>-0.063008</td>\n",
       "      <td>0.135935</td>\n",
       "      <td>-0.160517</td>\n",
       "      <td>-0.550089</td>\n",
       "      <td>1.070600</td>\n",
       "      <td>-0.831403</td>\n",
       "      <td>-0.532563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>-0.155570</td>\n",
       "      <td>-0.558999</td>\n",
       "      <td>-0.628423</td>\n",
       "      <td>0.435421</td>\n",
       "      <td>-0.724745</td>\n",
       "      <td>-0.209711</td>\n",
       "      <td>-0.226805</td>\n",
       "      <td>0.649486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-0.000957</td>\n",
       "      <td>0.267696</td>\n",
       "      <td>-0.395647</td>\n",
       "      <td>-0.071611</td>\n",
       "      <td>0.458861</td>\n",
       "      <td>-0.211226</td>\n",
       "      <td>-0.257202</td>\n",
       "      <td>-0.104325</td>\n",
       "      <td>0.536277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.118293</td>\n",
       "      <td>-0.035700</td>\n",
       "      <td>-0.043826</td>\n",
       "      <td>-0.301693</td>\n",
       "      <td>-0.097414</td>\n",
       "      <td>0.554063</td>\n",
       "      <td>0.058233</td>\n",
       "      <td>-0.629723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>-0.498040</td>\n",
       "      <td>0.097378</td>\n",
       "      <td>0.809618</td>\n",
       "      <td>-0.370430</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>0.194941</td>\n",
       "      <td>0.471016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.242250</td>\n",
       "      <td>-0.098755</td>\n",
       "      <td>-0.078896</td>\n",
       "      <td>-0.244518</td>\n",
       "      <td>0.649802</td>\n",
       "      <td>-0.399744</td>\n",
       "      <td>-0.295290</td>\n",
       "      <td>0.245229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.053834</td>\n",
       "      <td>0.146335</td>\n",
       "      <td>0.629590</td>\n",
       "      <td>-1.159198</td>\n",
       "      <td>0.128915</td>\n",
       "      <td>-0.701372</td>\n",
       "      <td>-0.015525</td>\n",
       "      <td>0.140969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>0.243053</td>\n",
       "      <td>0.031848</td>\n",
       "      <td>-0.051682</td>\n",
       "      <td>0.113996</td>\n",
       "      <td>-0.224008</td>\n",
       "      <td>0.819935</td>\n",
       "      <td>-0.874551</td>\n",
       "      <td>0.238472</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.181482</td>\n",
       "      <td>0.348306</td>\n",
       "      <td>-0.524237</td>\n",
       "      <td>0.278079</td>\n",
       "      <td>0.139213</td>\n",
       "      <td>0.054778</td>\n",
       "      <td>-0.065717</td>\n",
       "      <td>0.165694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  pcm_RMSenergy_sma_amean  pcm_fftMag_mfcc_sma[1]_amean  \\\n",
       "0    4.0                -0.000864                     -1.188091   \n",
       "1    5.0                -0.004605                      0.022244   \n",
       "2    8.0                 0.001767                     -0.545172   \n",
       "3   20.0                -0.003113                      0.120467   \n",
       "4   21.0                -0.000428                     -0.201158   \n",
       "5   23.0                -0.002165                     -0.024271   \n",
       "6   32.0                -0.001112                      0.432318   \n",
       "7   35.0                -0.003161                      0.366671   \n",
       "8   37.0                -0.000485                      0.394130   \n",
       "9   41.0                -0.000964                     -0.020902   \n",
       "10  42.0                 0.000033                      0.030377   \n",
       "11  44.0                 0.001722                     -0.155570   \n",
       "12  47.0                -0.000957                      0.267696   \n",
       "13  50.0                 0.000250                      0.118293   \n",
       "14  51.0                -0.000146                      0.074970   \n",
       "15  61.0                -0.000064                      0.242250   \n",
       "16  62.0                 0.000513                      0.053834   \n",
       "17  71.0                -0.001059                      0.243053   \n",
       "18  73.0                -0.000180                     -0.181482   \n",
       "\n",
       "    pcm_fftMag_mfcc_sma[2]_amean  pcm_fftMag_mfcc_sma[3]_amean  \\\n",
       "0                       1.458396                     -0.644212   \n",
       "1                       0.041306                      0.371020   \n",
       "2                      -0.233862                      0.693634   \n",
       "3                      -0.326470                      0.884765   \n",
       "4                      -0.268297                      0.201903   \n",
       "5                       0.128524                      0.470709   \n",
       "6                      -0.105907                      1.495445   \n",
       "7                       0.193564                     -0.023716   \n",
       "8                       0.261597                     -0.139036   \n",
       "9                       0.018043                      0.745624   \n",
       "10                     -0.063008                      0.135935   \n",
       "11                     -0.558999                     -0.628423   \n",
       "12                     -0.395647                     -0.071611   \n",
       "13                     -0.035700                     -0.043826   \n",
       "14                     -0.498040                      0.097378   \n",
       "15                     -0.098755                     -0.078896   \n",
       "16                      0.146335                      0.629590   \n",
       "17                      0.031848                     -0.051682   \n",
       "18                      0.348306                     -0.524237   \n",
       "\n",
       "    pcm_fftMag_mfcc_sma[4]_amean  pcm_fftMag_mfcc_sma[5]_amean  \\\n",
       "0                      -0.697069                     -0.543809   \n",
       "1                       1.856301                     -2.347585   \n",
       "2                      -1.303848                     -0.635333   \n",
       "3                      -0.090467                      0.182058   \n",
       "4                      -0.366338                      0.377646   \n",
       "5                       1.293796                     -1.696811   \n",
       "6                      -1.006755                      1.001877   \n",
       "7                       0.258827                      0.975375   \n",
       "8                       0.246072                      0.183514   \n",
       "9                       0.887429                     -3.439343   \n",
       "10                     -0.160517                     -0.550089   \n",
       "11                      0.435421                     -0.724745   \n",
       "12                      0.458861                     -0.211226   \n",
       "13                     -0.301693                     -0.097414   \n",
       "14                      0.809618                     -0.370430   \n",
       "15                     -0.244518                      0.649802   \n",
       "16                     -1.159198                      0.128915   \n",
       "17                      0.113996                     -0.224008   \n",
       "18                      0.278079                      0.139213   \n",
       "\n",
       "    pcm_fftMag_mfcc_sma[6]_amean  pcm_fftMag_mfcc_sma[7]_amean  \\\n",
       "0                       2.068849                     -1.118681   \n",
       "1                       2.857080                     -0.310527   \n",
       "2                       0.913341                     -0.946743   \n",
       "3                      -0.183817                      0.728905   \n",
       "4                       0.226589                     -0.530547   \n",
       "5                       3.038422                     -0.332586   \n",
       "6                       0.911382                     -0.181762   \n",
       "7                      -0.922304                      0.307595   \n",
       "8                       0.162386                     -0.175606   \n",
       "9                       1.431305                     -0.421041   \n",
       "10                      1.070600                     -0.831403   \n",
       "11                     -0.209711                     -0.226805   \n",
       "12                     -0.257202                     -0.104325   \n",
       "13                      0.554063                      0.058233   \n",
       "14                     -0.032356                      0.194941   \n",
       "15                     -0.399744                     -0.295290   \n",
       "16                     -0.701372                     -0.015525   \n",
       "17                      0.819935                     -0.874551   \n",
       "18                      0.054778                     -0.065717   \n",
       "\n",
       "    pcm_fftMag_mfcc_sma[8]_amean  ...  CAI Trait Dyadic Score  \\\n",
       "0                       0.597193  ...                0.153846   \n",
       "1                      -0.021322  ...                0.166667   \n",
       "2                      -0.024012  ...                0.133333   \n",
       "3                      -0.347066  ...                     NaN   \n",
       "4                       0.462883  ...                0.312500   \n",
       "5                      -0.556816  ...                     NaN   \n",
       "6                      -0.036236  ...                0.375000   \n",
       "7                      -0.030484  ...               -0.142857   \n",
       "8                      -0.127135  ...                0.176471   \n",
       "9                      -1.802264  ...                0.217391   \n",
       "10                     -0.532563  ...               -0.312500   \n",
       "11                      0.649486  ...               -0.333333   \n",
       "12                      0.536277  ...               -0.111111   \n",
       "13                     -0.629723  ...                0.125000   \n",
       "14                      0.471016  ...                0.050000   \n",
       "15                      0.245229  ...                0.266667   \n",
       "16                      0.140969  ...                0.263158   \n",
       "17                      0.238472  ...                     NaN   \n",
       "18                      0.165694  ...                0.125000   \n",
       "\n",
       "    CAI Trait Small group Score  Age  Gender  Lang  college  presentation  \\\n",
       "0                      0.047619  3.0     1.0   2.0      1.0           2.0   \n",
       "1                      0.090909  2.0     2.0   2.0      1.0           1.0   \n",
       "2                      0.083333  1.0     2.0   1.0      1.0           3.0   \n",
       "3                           NaN  1.0     1.0   2.0      3.0           1.0   \n",
       "4                           NaN  1.0     1.0   1.0      1.0           2.0   \n",
       "5                     -0.058824  1.0     1.0   1.0      1.0           2.0   \n",
       "6                     -0.181818  2.0     2.0   2.0      1.0           2.0   \n",
       "7                      0.125000  1.0     2.0   1.0      3.0           4.0   \n",
       "8                     -0.083333  1.0     1.0   NaN      4.0           2.0   \n",
       "9                      0.050000  2.0     2.0   1.0      1.0           3.0   \n",
       "10                    -0.040000  1.0     1.0   1.0      3.0           5.0   \n",
       "11                    -0.400000  1.0     1.0   1.0      4.0           2.0   \n",
       "12                          NaN  1.0     2.0   1.0      3.0           2.0   \n",
       "13                     0.105263  1.0     2.0   2.0      3.0           2.0   \n",
       "14                    -0.066667  1.0     2.0   1.0      3.0           1.0   \n",
       "15                     0.333333  1.0     2.0   1.0      2.0           2.0   \n",
       "16                     0.045455  2.0     2.0   2.0      1.0           2.0   \n",
       "17                          NaN  1.0     2.0   1.0      1.0           2.0   \n",
       "18                     0.222222  1.0     2.0   1.0      1.0           1.0   \n",
       "\n",
       "    ethnicity  presentation_3_months  highest_education  \n",
       "0         1.0                    0.0                3.0  \n",
       "1         1.0                    1.0                2.0  \n",
       "2         2.0                    2.0                1.0  \n",
       "3         2.0                    2.0                1.0  \n",
       "4         2.0                    0.0                1.0  \n",
       "5         2.0                    0.0                1.0  \n",
       "6         1.0                    1.0                2.0  \n",
       "7         1.0                    2.0                1.0  \n",
       "8         3.0                    1.0                1.0  \n",
       "9         3.0                    2.0                2.0  \n",
       "10        2.0                    1.0                1.0  \n",
       "11        2.0                    1.0                1.0  \n",
       "12        4.0                    1.0                1.0  \n",
       "13        4.0                    1.0                1.0  \n",
       "14        1.0                    1.0                1.0  \n",
       "15        4.0                    2.0                1.0  \n",
       "16        1.0                    0.0                2.0  \n",
       "17        3.0                    1.0                1.0  \n",
       "18        3.0                    2.0                1.0  \n",
       "\n",
       "[19 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################\n",
    "# Get slopes from linear regression of the 8 trials for each ID\n",
    "###############################################################\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def get_slopes(data, start, end):\n",
    "    y0 = data['trial'].to_numpy(copy=True)\n",
    "\n",
    "    slopes = pd.DataFrame(np.zeros((19, 50)), columns=data.columns)\n",
    "    slopes = slopes.drop([\"trial\"], axis=1)\n",
    "\n",
    "    for col in range(2, 34):\n",
    "        x1 = data[data.columns[col]]\n",
    "        y0 = list(range(start, end + 1))\n",
    "        for row in range(19):\n",
    "            x0 = x1[ (row * 8) + start - 1 : (row * 8) + end ].to_numpy()\n",
    "            x = np.array([])\n",
    "            y = np.array([])\n",
    "            \n",
    "            slopes.iloc[row, 0] = data.iloc[row * 8, 0]\n",
    "\n",
    "            for i in range(len(x0)):  # remove NaN from data\n",
    "                if not math.isnan(x0[i]) and not math.isnan(y0[i]):\n",
    "                    x = np.append(x, x0[i])\n",
    "                    y = np.append(y, y0[i])\n",
    "            \n",
    "            try:\n",
    "                reg = LinearRegression().fit(y.reshape(-1,1),x)\n",
    "                slopes.iloc[row, col - 1] = reg.coef_\n",
    "            except:\n",
    "                 slopes.iloc[row, col - 1] = 0\n",
    "    \n",
    "    for col in range(34, 50):\n",
    "        for row in range(19):\n",
    "            slopes.iloc[row, col - 1] = data.iloc[row * 8, col]\n",
    "            \n",
    "    # Want to preserve zeros in the demographic data, so temporarily boost it up one...\n",
    "    for col in range(43, 50):\n",
    "        for row in range(19):\n",
    "            slopes.iloc[row, col - 1] += 1.0\n",
    "                    \n",
    "    slopes.replace(0, np.NaN, inplace=True)\n",
    "    \n",
    "    # Then bump it back down. (I know this is a dumb way to do this.)\n",
    "    for col in range(43, 50):\n",
    "        for row in range(19):\n",
    "            slopes.iloc[row, col - 1] -= 1.0\n",
    "    \n",
    "    return slopes\n",
    "\n",
    "all_slopes = get_slopes(all_data, 1, 8)\n",
    "slope_ids = all_slopes['id'].to_list()\n",
    "#slope_ids\n",
    "all_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#y_columns = change_data.columns.to_list()[1:]\n",
    "y_columns = ['Brief fear of Negative Evaluation', 'CAI State Score', 'CAI Trait Full Score', 'STAI State Score', 'CAI Trait Public Speaking Score', 'STAI Trait Score', 'CAI Trait Dyadic Score', 'CAI Trait Small group Score']\n",
    "\n",
    "def get_combo_predictions(X0, slope_data):\n",
    "    corrs = []\n",
    "    ps = []\n",
    "    for y_col, y_i in zip(y_columns, range(len(y_columns))):\n",
    "        y0 = slope_data[y_col].to_numpy(copy=True)\n",
    "        X = np.array([X0[0]])\n",
    "        y = np.array(y0[0])\n",
    "        \n",
    "        for i in range(1,len(X0)):  # remove NaN from data\n",
    "            is_nan = False\n",
    "            for x in X0[i]:\n",
    "                if math.isnan(x):\n",
    "                    is_nan = True\n",
    "                    break\n",
    "            if not math.isnan(y0[i]) and not is_nan:\n",
    "                X = np.append(X, [X0[i]], axis=0)\n",
    "                y = np.append(y, y0[i])\n",
    "            \n",
    "        folds = min(10, len(X))\n",
    "        model = LinearRegression()\n",
    "        cv = KFold(folds, shuffle=True, random_state=42)\n",
    "        predicted_vals0 = cross_val_predict(model, X, y, cv=cv)\n",
    "        actual_vals0 = slope_data[y_col].to_numpy(copy=True)\n",
    "        predicted_vals = []\n",
    "        actual_vals = []\n",
    "        \n",
    "\n",
    "        for j in range(len(predicted_vals0)):\n",
    "            if not math.isnan(predicted_vals0[j]) and not math.isnan(actual_vals0[j]):\n",
    "                predicted_vals.append(predicted_vals0[j])\n",
    "                actual_vals.append(actual_vals0[j])\n",
    "\n",
    "        correlation, pval = pearsonr(predicted_vals, actual_vals)\n",
    "        #to_print = str(correlation) + str(pval)\n",
    "        #if pval < 0.15: \n",
    "        #    if not folds == 10:\n",
    "        #        print(\"With # KFolds\", folds)\n",
    "        #    print(\"{0}:\\t\\t{1}\\t\\t{2}\\t{3}\\t\\t{4}\".format(y_col, correlation, pval, \"Rows:\", len(y)))\n",
    "        corrs.append(correlation)\n",
    "        ps.append(pval)\n",
    "        \n",
    "    return corrs, ps\n",
    "      \n",
    "def generate_combos(slope_data):\n",
    "    group_c = []\n",
    "    group_p = []\n",
    "    group_titles = []\n",
    "\n",
    "    group_titles.append('mfcc1-12')\n",
    "    X0_mfcc = slope_data[slope_data.columns[2:14]].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_mfcc, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('pauses')\n",
    "    X0_pauses = slope_data[slope_data.columns[17:20]].to_numpy(copy=True) # #pause, pause_frequency, pause_interval\n",
    "    c, p = get_combo_predictions(X0_pauses, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('mfccs + pauses')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[17:20].to_list()\n",
    "    X0_pauses = slope_data[columns].to_numpy(copy=True) # #pause, pause_frequency, pause_interval\n",
    "    c, p = get_combo_predictions(X0_pauses, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('jitter, shimmer')\n",
    "    X0_jitter = slope_data[slope_data.columns[22:24]].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_jitter, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('mfccs+ jitter, shimmer')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[22:24].to_list()\n",
    "    X0_jitter = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_jitter, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append(\"all bio\")\n",
    "    X0_eda = slope_data[slope_data.columns[23:30]].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_eda, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('bio + mfcc')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[23:30].to_list()\n",
    "    X0_bio_mfcc = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_bio_mfcc, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "    \n",
    "    #return group_c, group_p, group_titles\n",
    "\n",
    "    # All mfcc's combined with other attributes\n",
    "    for i in range(14, 25):\n",
    "        title = \"mfccs + \" + str(slope_data.columns[i])\n",
    "        group_titles.append(title)\n",
    "        columns = slope_data.columns[2:14].to_list() + [slope_data.columns[i]]\n",
    "        X0 = slope_data[columns].to_numpy(copy=True)\n",
    "        c,p = get_combo_predictions(X0, slope_data)\n",
    "        group_c.append(c)\n",
    "        group_p.append(p)\n",
    "\n",
    "    for i in range(14, 25):\n",
    "        col1 = slope_data.columns[i]\n",
    "        for j in range(i + 1, 25):\n",
    "            col2 = slope_data.columns[j]\n",
    "            title = str(col1) + '+' + str(col2)\n",
    "            group_titles.append(title)\n",
    "            X0 = slope_data[[col1, col2]].to_numpy(copy=True)\n",
    "            c, p = get_combo_predictions(X0, slope_data)\n",
    "            group_c.append(c)\n",
    "            group_p.append(p)\n",
    "\n",
    "    for i in range(14, 25):\n",
    "        col1 = slope_data.columns[i]\n",
    "        for j in range(i + 1, 25):\n",
    "            col2 = slope_data.columns[j]\n",
    "            columns = slope_data.columns[2:14].to_list() + [col1] + [col2]\n",
    "            title = \"mfccs + \" + str(col1) + '+' + str(col2)\n",
    "            group_titles.append(title)\n",
    "            X0 = slope_data[[col1, col2]].to_numpy(copy=True)\n",
    "            c, p = get_combo_predictions(X0, slope_data)\n",
    "            group_c.append(c)\n",
    "            group_p.append(p)\n",
    "\n",
    "    for i in range(14, 24):\n",
    "        col = slope_data.columns[i]\n",
    "        title = 'bio +' + str(col)\n",
    "        group_titles.append(title)\n",
    "        columns = slope_data.columns[23:30].to_list() + [col]\n",
    "        X0_eda = slope_data[columns].to_numpy(copy=True)\n",
    "        c,p = get_combo_predictions(X0_eda, slope_data)\n",
    "        group_c.append(c)\n",
    "        group_p.append(p)\n",
    "\n",
    "    for i in range(14, 24):\n",
    "        col = slope_data.columns[i]\n",
    "        title = 'mfcc + bio +' + str(col)\n",
    "        group_titles.append(title)\n",
    "        columns = slope_data.columns[2:14].to_list() + slope_data.columns[23:30].to_list() + [col]\n",
    "        X0_eda = slope_data[columns].to_numpy(copy=True)\n",
    "        c,p = get_combo_predictions(X0_eda, slope_data)\n",
    "        group_c.append(c)\n",
    "        group_p.append(p)\n",
    "        \n",
    "    return group_c, group_p, group_titles\n",
    "\n",
    "#group_c, group_p, group_titles = generate_combos(all_slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def generate_graphs(c, p, titles, specifier):\n",
    "    short_y_col = [\"BFNE (19)\", \"CAI St(19)\", \"CAI F(18)\" , \"STAI St(18)\", \"CAI PS(17)\", \"STAI T(17)\", \"CAI Dy (16)\", \"CAI Sm(15)\"]\n",
    "    correlations = np.matrix(c)\n",
    "    pvalues = np.matrix(p)\n",
    "\n",
    "    correlations = np.round(correlations, decimals=2)\n",
    "    pvalues = np.round(pvalues, decimals=2)\n",
    "    \n",
    "    data = [correlations, pvalues]\n",
    "    graph_titles = [\"correlations_\" + specifier + \".png\", \"pvalues_\" + specifier + \".png\"]\n",
    "    \n",
    "    for k in range(2):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,85))\n",
    "        \n",
    "        if k == 0:\n",
    "            p = ax.pcolor(data[k], vmin=-0.5, vmax=0.8)\n",
    "        else:\n",
    "            p = ax.pcolor(data[k], vmin = 0.0, vmax = 1.0)\n",
    "        #p = ax.matshow(data[k])\n",
    "        fig.colorbar(p, ax=ax, fraction=0.05, pad=0.04)\n",
    "        ax.set_xticklabels(labels=short_y_col)\n",
    "        ax.set_yticklabels(labels=titles)\n",
    "        plt.yticks(np.arange(0, len(titles), 1.0))\n",
    "        for tick in ax.get_xticklabels():\n",
    "            tick.set_rotation(30)  \n",
    "\n",
    "        for i in range(len(short_y_col)):\n",
    "            for j in range(len(titles)):\n",
    "                text = ax.text(i + 0.5, j + 0.5, data[k][j, i], ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(DATA_PATH + graph_titles[k])\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "for i in range(2,9):\n",
    "    s = get_slopes(all_data, 1, i)\n",
    "    c, p, titles = generate_combos(s)\n",
    "    t = \"upto\" + str(i)\n",
    "    generate_graphs(c, p, titles, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_by_demo(slopes):\n",
    "    slopes.dropna(inplace=True)\n",
    "    age1 = slopes[slopes.Age == 1.0]\n",
    "    age2 = slopes[slopes.Age == 2.0]\n",
    "    age3 = slopes[slopes.Age == 3.0]\n",
    "    gender1 = slopes[slopes.Gender == 1.0]\n",
    "    gender2 = slopes[slopes.Gender == 2.0]\n",
    "    college1 = slopes[slopes.college == 1.0]\n",
    "    college2 = slopes[slopes.college == 2.0]\n",
    "    college3 = slopes[slopes.college == 3.0]\n",
    "    college4 = slopes[slopes.college == 4.0]\n",
    "    ethnicity1 = slopes[slopes.ethnicity == 1.0]\n",
    "    ethnicity2 = slopes[slopes.ethnicity == 2.0]\n",
    "    ethnicity3 = slopes[slopes.ethnicity == 3.0]\n",
    "    ethnicity4 = slopes[slopes.ethnicity == 4.0]\n",
    "    presentation0 = slopes[slopes.presentation_3_months == 0.0]\n",
    "    presentation1 = slopes[slopes.presentation_3_months == 1.0]\n",
    "    presentation2 = slopes[slopes.presentation_3_months == 2.0]\n",
    "    edu1 = slopes[slopes.highest_education == 1.0]\n",
    "    edu2 = slopes[slopes.highest_education == 2.0]\n",
    "    edu3 = slopes[slopes.highest_education == 2.0]\n",
    "    \n",
    "    all_demos = [age1, age2, age3, gender1, gender2, college1, \n",
    "                 college2, college3, college4, ethnicity1, \n",
    "                 ethnicity2, ethnicity3, ethnicity4, presentation0,\n",
    "                presentation1, presentation2, edu1, edu2, edu3]\n",
    "    demo_titles = [\"age1\", \"age2\", \"age3\", \"gender1\", \"gender2\", \"college1\", \"college2\", \n",
    "                   \"college3\", \"college4\", \"ethnicity1\", \"ethnicity2\", \"ethnicity3\", \n",
    "                   \"ethnicity4\", \"presentation0\", \"presentation1\", \"presentation2\", \"edu1\", \n",
    "                   \"edu2\", \"edu3\"]\n",
    "    \n",
    "    for d, t in zip(all_demos, demo_titles):\n",
    "        if d.shape[0] < 3:\n",
    "            continue\n",
    "        print(t, \"had\", d.shape[0], \"samples\")\n",
    "        c, p, titles = generate_combos(d)\n",
    "        print(\"Finished\", t)\n",
    "        generate_graphs(c, p, titles, t)\n",
    "        \n",
    "analyze_by_demo(all_slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combos_with_demo(slope_data, demo_col):\n",
    "    group_c = []\n",
    "    group_p = []\n",
    "    group_titles = []\n",
    "\n",
    "    group_titles.append('mfcc1-12')\n",
    "    columns = slope_data.columns[2:14].to_list() + [demo_col]\n",
    "    X0_mfcc = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_mfcc, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('pauses')\n",
    "    columns = slope_data.columns[17:20].to_list() + [demo_col]\n",
    "    X0_pauses = slope_data[columns].to_numpy(copy=True) # #pause, pause_frequency, pause_interval\n",
    "    c, p = get_combo_predictions(X0_pauses, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('mfccs + pauses')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[17:20].to_list() + [demo_col]\n",
    "    X0_pauses = slope_data[columns].to_numpy(copy=True) # #pause, pause_frequency, pause_interval\n",
    "    c, p = get_combo_predictions(X0_pauses, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('jitter, shimmer')\n",
    "    columns = slope_data.columns[22:24].to_list() + [demo_col]\n",
    "    X0_jitter = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_jitter, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('mfccs+ jitter, shimmer')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[22:24].to_list() + [demo_col]\n",
    "    X0_jitter = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_jitter, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append(\"all bio\")\n",
    "    columns = slope_data.columns[23:30].to_list() + [demo_col]\n",
    "    X0_eda = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_eda, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('bio + mfcc')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[23:30].to_list() + [demo_col]\n",
    "    X0_bio_mfcc = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_bio_mfcc, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "    \n",
    "    #return group_c, group_p, group_titles\n",
    "\n",
    "    # All mfcc's combined with other attributes\n",
    "    for i in range(14, 25):\n",
    "        title = \"mfccs + \" + str(slope_data.columns[i])\n",
    "        group_titles.append(title)\n",
    "        columns = slope_data.columns[2:14].to_list() + [slope_data.columns[i]] + [demo_col]\n",
    "        X0 = slope_data[columns].to_numpy(copy=True)\n",
    "        c,p = get_combo_predictions(X0, slope_data)\n",
    "        group_c.append(c)\n",
    "        group_p.append(p)\n",
    "\n",
    "    for i in range(14, 25):\n",
    "        col1 = slope_data.columns[i]\n",
    "        for j in range(i + 1, 25):\n",
    "            col2 = slope_data.columns[j]\n",
    "            title = str(col1) + '+' + str(col2)\n",
    "            group_titles.append(title)\n",
    "            X0 = slope_data[[col1, col2, demo_col]].to_numpy(copy=True)\n",
    "            c, p = get_combo_predictions(X0, slope_data)\n",
    "            group_c.append(c)\n",
    "            group_p.append(p)\n",
    "\n",
    "    for i in range(14, 25):\n",
    "        col1 = slope_data.columns[i]\n",
    "        for j in range(i + 1, 25):\n",
    "            col2 = slope_data.columns[j]\n",
    "            columns = slope_data.columns[2:14].to_list() + [col1] + [col2] + [demo_col]\n",
    "            title = \"mfccs + \" + str(col1) + '+' + str(col2)\n",
    "            group_titles.append(title)\n",
    "            X0 = slope_data[[col1, col2]].to_numpy(copy=True)\n",
    "            c, p = get_combo_predictions(X0, slope_data)\n",
    "            group_c.append(c)\n",
    "            group_p.append(p)\n",
    "\n",
    "    for i in range(14, 24):\n",
    "        col = slope_data.columns[i]\n",
    "        title = 'bio +' + str(col)\n",
    "        group_titles.append(title)\n",
    "        columns = slope_data.columns[23:30].to_list() + [col] + [demo_col]\n",
    "        X0_eda = slope_data[columns].to_numpy(copy=True)\n",
    "        c,p = get_combo_predictions(X0_eda, slope_data)\n",
    "        group_c.append(c)\n",
    "        group_p.append(p)\n",
    "\n",
    "    for i in range(14, 24):\n",
    "        col = slope_data.columns[i]\n",
    "        title = 'mfcc + bio +' + str(col)\n",
    "        group_titles.append(title)\n",
    "        columns = slope_data.columns[2:14].to_list() + slope_data.columns[23:30].to_list() + [col] + [demo_col]\n",
    "        X0_eda = slope_data[columns].to_numpy(copy=True)\n",
    "        c,p = get_combo_predictions(X0_eda, slope_data)\n",
    "        group_c.append(c)\n",
    "        group_p.append(p)\n",
    "        \n",
    "    return group_c, group_p, group_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for demo_title in demo_data.columns.to_list():\n",
    "    #print(demo_title)\n",
    "    c, p, titles = generate_combos_with_demo(all_slopes, demo_title)\n",
    "    generate_graphs(c, p, titles, demo_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(X0, slope_data):\n",
    "    corrs = []\n",
    "    ps = []\n",
    "    for y_col, y_i in zip(y_columns, range(len(y_columns))):\n",
    "        y0 = slope_data[y_col].to_numpy(copy=True)\n",
    "        X = np.array(X0[0])\n",
    "        y = np.array(y0[0])\n",
    "        \n",
    "        for i in range(1,len(X0)):  # remove NaN from data\n",
    "            if math.isnan(y0[i]) or math.isnan(X0[i]):\n",
    "                continue\n",
    "            else:\n",
    "                X = np.append(X, X0[i])\n",
    "                y = np.append(y, y0[i])\n",
    "            \n",
    "        X = X.reshape(-1, 1)\n",
    "        folds = min(10, len(X))\n",
    "        model = LinearRegression()\n",
    "        cv = KFold(folds, shuffle=True, random_state=42)\n",
    "        predicted_vals0 = cross_val_predict(model, X, y, cv=cv)\n",
    "        actual_vals0 = slope_data[y_col].to_numpy(copy=True)\n",
    "        predicted_vals = []\n",
    "        actual_vals = []\n",
    "        \n",
    "\n",
    "        for j in range(len(predicted_vals0)):\n",
    "            if not math.isnan(predicted_vals0[j]) and not math.isnan(actual_vals0[j]):\n",
    "                predicted_vals.append(predicted_vals0[j])\n",
    "                actual_vals.append(actual_vals0[j])\n",
    "\n",
    "        correlation, pval = pearsonr(predicted_vals, actual_vals)\n",
    "        #to_print = str(correlation) + str(pval)\n",
    "        #if pval < 0.15: \n",
    "        #    if not folds == 10:\n",
    "        #        print(\"With # KFolds\", folds)\n",
    "        #    print(\"{0}:\\t\\t{1}\\t\\t{2}\\t{3}\\t\\t{4}\".format(y_col, correlation, pval, \"Rows:\", len(y)))\n",
    "        corrs.append(correlation)\n",
    "        ps.append(pval)\n",
    "        \n",
    "    return corrs, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = all_slopes['Age'].to_numpy(copy=True)\n",
    "c, p = get_predictions(X0, all_slopes)\n",
    "generate_graphs([c], [p], ['age'], 'just-age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
