{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 7,
>>>>>>> parent of b00050f... work since last week
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.179487\n",
       "1     -0.179487\n",
       "2     -0.179487\n",
       "3     -0.179487\n",
       "4     -0.179487\n",
       "         ...   \n",
       "147    0.178571\n",
       "148    0.178571\n",
       "149    0.178571\n",
       "150    0.178571\n",
       "151    0.178571\n",
       "Name: CAI State Score, Length: 152, dtype: float64"
      ]
     },
<<<<<<< HEAD
     "execution_count": 2,
=======
     "execution_count": 7,
>>>>>>> parent of b00050f... work since last week
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "#############################\n",
    "# Import and combine all data\n",
    "#############################\n",
    "\n",
    "\n",
    "DATA_PATH = \"/Users/mvonebers/HUBBS-Lab/data/\"\n",
    "#DATA_PATH = \"/home/maggie/HUBBS-Lab/data/\"\n",
    "\n",
    "e4_data = pd.read_excel(DATA_PATH + \"E4_TEST.xlsx\")\n",
    "change_data = pd.read_excel(DATA_PATH + \"normalized_change.xlsx\")\n",
    "audio_data = pd.read_excel(DATA_PATH + \"audio_TEST.xlsx\")\n",
    "demo_data = pd.read_csv(DATA_PATH + \"Demographics Information.csv\")\n",
    "\n",
    "\n",
    "# Break apart the ID column into \"person\" and \"trial\"\n",
    "def clean_id(data):\n",
    "    data.insert(0, \"person\", [0] * data.shape[0])\n",
    "    data.insert(1, \"trial\", [0] * data.shape[0])\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        data.at[i, \"person\"] = int(data.at[i, \"id\"][7:])\n",
    "        data.at[i, \"trial\"] = int(data.at[i, \"id\"][5])\n",
    "    \n",
    "    data = data.drop(columns=['id'])\n",
    "    data = data.rename(columns={\"person\": \"id\"})\n",
    "    return data\n",
    "\n",
    "    \n",
    "e4_data = clean_id(e4_data)\n",
    "audio_data = clean_id(audio_data)    \n",
    "    \n",
    "all_data = pd.merge(e4_data, change_data, on='id')\n",
    "all_data = audio_data.merge(all_data, how='right')\n",
    "\n",
    "\n",
    "# Reorder survey data in order of most samples to least\n",
    "columns = all_data.columns.to_list()\n",
    "new_columns = deepcopy(columns)\n",
    "new_columns[35] = columns[40]\n",
    "new_columns[37] = columns[41] \n",
    "new_columns[38] = columns[37] \n",
    "new_columns[40] = columns[35]\n",
    "new_columns[41] = columns[38]\n",
    "\n",
    "all_data = all_data[new_columns]\n",
    "\n",
    "\n",
    "# what does this do?\n",
    "#demo_ids = demo_data['id'].to_list()\n",
    "#\n",
    "#for id_ in demo_ids:\n",
    "#    if id_ not in slope_ids:\n",
    "#        demo_data = demo_data[demo_data.id != id_]\n",
    "        \n",
    "all_data = all_data.merge(demo_data, how=\"right\")\n",
    "\n",
    "# The demographic data lists IDs that aren't present in the other data, so remove them\n",
    "all_data = all_data[all_data.id != 16]\n",
    "all_data = all_data[all_data.id != 27]\n",
    "all_data = all_data[all_data.id != 38]\n",
    "all_data = all_data[all_data.id != 43]\n",
    "all_data = all_data[all_data.id != 46]\n",
    "all_data = all_data[all_data.id != 49]\n",
    "all_data = all_data[all_data.id != 53]\n",
    "all_data = all_data[all_data.id != 58]\n",
    "all_data = all_data[all_data.id != 65]\n",
    "all_data = all_data[all_data.id != 66]\n",
    "\n",
    "all_data.drop(['CAI Trait Small group Score', 'CAI Trait Dyadic Score', 'CAI Trait Public Speaking Score', 'STAI State Score', 'Brief fear of Negative Evaluation'], axis=1, inplace=True)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 6,
>>>>>>> parent of b00050f... work since last week
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 id\n",
      "1 pcm_RMSenergy_sma_amean\n",
      "2 pcm_fftMag_mfcc_sma[1]_amean\n",
      "3 pcm_fftMag_mfcc_sma[2]_amean\n",
      "4 pcm_fftMag_mfcc_sma[3]_amean\n",
      "5 pcm_fftMag_mfcc_sma[4]_amean\n",
      "6 pcm_fftMag_mfcc_sma[5]_amean\n",
      "7 pcm_fftMag_mfcc_sma[6]_amean\n",
      "8 pcm_fftMag_mfcc_sma[7]_amean\n",
      "9 pcm_fftMag_mfcc_sma[8]_amean\n",
      "10 pcm_fftMag_mfcc_sma[9]_amean\n",
      "11 pcm_fftMag_mfcc_sma[10]_amean\n",
      "12 pcm_fftMag_mfcc_sma[11]_amean\n",
      "13 pcm_fftMag_mfcc_sma[12]_amean\n",
      "14 pcm_zcr_sma_amean\n",
      "15 voiceProb_sma_amean\n",
      "16 F0_sma_amean\n",
      "17 #pause\n",
      "18 pause_frequency\n",
      "19 pause_interval\n",
      "20 mean\n",
      "21 percent\n",
      "22 jitterLocal_sma_amean\n",
      "23 jitterDDP_sma_amean\n",
      "24 shimmerLocal_sma_amean\n",
      "25 EDA_PPT\n",
      "26 HR_PPT\n",
      "27 TEMP_PPT\n",
      "28 BVP_PPT\n",
      "29 ACC_PPT\n",
      "30 IBI_PPT\n",
      "31 EDA_FREQ_PPT\n",
      "32 EDA_AMP_PPT\n",
<<<<<<< HEAD
      "33 CAI State Score\n",
      "34 CAI Trait Full Score\n",
      "35 STAI Trait Score\n",
      "36 Age\n",
      "37 Gender\n",
      "38 Lang\n",
      "39 college\n",
      "40 presentation\n",
      "41 ethnicity\n",
      "42 presentation_3_months\n",
      "43 highest_education\n"
=======
      "33 Brief fear of Negative Evaluation\n",
      "34 CAI State Score\n",
      "35 CAI Trait Full Score\n",
      "36 STAI Trait Score\n",
      "37 Age\n",
      "38 Gender\n",
      "39 Lang\n",
      "40 college\n",
      "41 presentation\n",
      "42 ethnicity\n",
      "43 presentation_3_months\n",
      "44 highest_education\n"
>>>>>>> parent of b00050f... work since last week
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# Get slopes from linear regression of the 8 trials for each ID\n",
    "###############################################################\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def get_slopes(data, start, end):\n",
    "    y0 = data['trial'].to_numpy(copy=True)\n",
    "\n",
    "    slopes = pd.DataFrame(np.zeros((19, 46)), columns=data.columns)\n",
    "    slopes = slopes.drop([\"trial\"], axis=1)\n",
    "\n",
    "    for col in range(2, 34):\n",
    "        x1 = data[data.columns[col]]\n",
    "        y0 = list(range(start, end + 1))\n",
    "        for row in range(19):\n",
    "            x0 = x1[ (row * 8) + start - 1 : (row * 8) + end ].to_numpy()\n",
    "            x = np.array([])\n",
    "            y = np.array([])\n",
    "            \n",
    "            slopes.iloc[row, 0] = data.iloc[row * 8, 0]\n",
    "\n",
    "            for i in range(len(x0)):  # remove NaN from data\n",
    "                if not math.isnan(x0[i]) and not math.isnan(y0[i]):\n",
    "                    x = np.append(x, x0[i])\n",
    "                    y = np.append(y, y0[i])\n",
    "            \n",
    "            try:\n",
    "                reg = LinearRegression().fit(y.reshape(-1,1),x)\n",
    "                slopes.iloc[row, col - 1] = reg.coef_\n",
    "            except:\n",
    "                 slopes.iloc[row, col - 1] = 0\n",
    "    \n",
    "    for col in range(34, 46):\n",
    "        for row in range(19):\n",
    "            slopes.iloc[row, col - 1] = data.iloc[row * 8, col]\n",
    "            \n",
    "    # Want to preserve zeros in the demographic data, so temporarily boost it up one...\n",
    "    for col in range(43, 46):\n",
    "        for row in range(19):\n",
    "            slopes.iloc[row, col - 1] += 1.0\n",
    "                    \n",
    "    slopes.replace(0, np.NaN, inplace=True)\n",
    "    \n",
    "    # Then bump it back down. (I know this is a dumb way to do this.)\n",
    "    for col in range(43, 46):\n",
    "        for row in range(19):\n",
    "            slopes.iloc[row, col - 1] -= 1.0\n",
    "    \n",
    "    return slopes\n",
    "\n",
    "all_slopes = get_slopes(all_data, 1, 8)\n",
    "slope_ids = all_slopes['id'].to_list()\n",
    "#slope_ids\n",
    "all_slopes\n",
    "\n",
    "for i, col in zip(range(len(all_slopes.columns.to_list())), all_slopes.columns.to_list()):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 3,
>>>>>>> parent of b00050f... work since last week
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "y_columns = change_data.columns.to_list()[1:]\n",
    "\n",
    "def get_combo_predictions(X0, slope_data):\n",
    "    corrs = []\n",
    "    ps = []\n",
    "    for y_col, y_i in zip(y_columns, range(len(y_columns))):\n",
    "        y0 = slope_data[y_col].to_numpy(copy=True)\n",
    "        X = np.array([X0[0]])\n",
    "        y = np.array(y0[0])\n",
    "        \n",
    "        for i in range(1,len(X0)):  # remove NaN from data\n",
    "            is_nan = False\n",
    "            for x in X0[i]:\n",
    "                if math.isnan(x):\n",
    "                    is_nan = True\n",
    "                    break\n",
    "            if not math.isnan(y0[i]) and not is_nan:\n",
    "                X = np.append(X, [X0[i]], axis=0)\n",
    "                y = np.append(y, y0[i])\n",
    "            \n",
    "        folds = min(10, len(X))\n",
    "        model = LinearRegression()\n",
    "        cv = KFold(folds, shuffle=True, random_state=42)\n",
    "        predicted_vals0 = cross_val_predict(model, X, y, cv=cv)\n",
    "        actual_vals0 = slope_data[y_col].to_numpy(copy=True)\n",
    "        predicted_vals = []\n",
    "        actual_vals = []\n",
    "        \n",
    "\n",
    "        for j in range(len(predicted_vals0)):\n",
    "            if not math.isnan(predicted_vals0[j]) and not math.isnan(actual_vals0[j]):\n",
    "                predicted_vals.append(predicted_vals0[j])\n",
    "                actual_vals.append(actual_vals0[j])\n",
    "\n",
    "        correlation, pval = pearsonr(predicted_vals, actual_vals)\n",
    "        #to_print = str(correlation) + str(pval)\n",
    "        #if pval < 0.15: \n",
    "        #    if not folds == 10:\n",
    "        #        print(\"With # KFolds\", folds)\n",
    "        #    print(\"{0}:\\t\\t{1}\\t\\t{2}\\t{3}\\t\\t{4}\".format(y_col, correlation, pval, \"Rows:\", len(y)))\n",
    "        corrs.append(correlation)\n",
    "        ps.append(pval)\n",
    "        \n",
    "    return corrs, ps\n",
    "      \n",
    "def generate_combos(slope_data):\n",
    "    group_c = []\n",
    "    group_p = []\n",
    "    group_titles = []\n",
    "    \n",
<<<<<<< HEAD
    "    #group_titles.append('age, language, ethnicity, highest edu')\n",
    "    #columns_demo = [slope_data.columns[36], slope_data.columns[38], slope_data.columns[41], slope_data.columns[43]]\n",
    "    #X0_demo = slope_data[columns_demo].to_numpy(copy=True)\n",
    "    #c,p = get_combo_predictions(X0_demo, slope_data)\n",
    "    #group_c.append(c)\n",
    "    #group_p.append(p)\n",
    "    \n",
    "    #group_titles.append(\"bios + demos\")\n",
    "    #columns = slope_data.columns[23:30].to_list() + columns_demo\n",
    "    #X0 = slope_data[columns].to_numpy(copy=True)\n",
    "    #c, p = get_combo_predictions(X0, slope_data)\n",
    "    #group_c.append(c)\n",
    "    #group_p.append(p)\n",
    "    \n",
    "    #group_titles.append('mfcc1-12 + demos')\n",
    "    #columns = slope_data.columns[2:14].to_list() + columns_demo\n",
    "    #X0 = slope_data[columns].to_numpy(copy=True)\n",
    "    #c,p = get_combo_predictions(X0, slope_data)\n",
    "    #group_c.append(c)\n",
    "    #group_p.append(p)\n",
=======
    "    group_titles.append('all demos')\n",
    "    X0_demo = slope_data[slope_data.columns[37:44]].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_demo, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "    \n",
    "    \n",
    "    group_titles.append(\"bios + demos\")\n",
    "    columns = slope_data.columns[23:30].to_list() + slope_data.columns[37:44].to_list()\n",
    "    X0 = slope_data[columns].to_numpy(copy=True)\n",
    "    c, p = get_combo_predictions(X0, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "    \n",
    "    group_titles.append('mfcc1-12 + demos')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[37:44].to_list()\n",
    "    X0 = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('mfcc1-12')\n",
    "    X0_mfcc = slope_data[slope_data.columns[2:14]].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_mfcc, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
>>>>>>> parent of b00050f... work since last week
    "\n",
    "    group_titles.append('pauses')\n",
    "    X0_pauses = slope_data[slope_data.columns[17:20]].to_numpy(copy=True) # #pause, pause_frequency, pause_interval\n",
    "    c, p = get_combo_predictions(X0_pauses, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('mfccs + pauses')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[17:20].to_list()\n",
    "    X0_pauses = slope_data[columns].to_numpy(copy=True) # #pause, pause_frequency, pause_interval\n",
    "    c, p = get_combo_predictions(X0_pauses, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('jitter, shimmer')\n",
    "    X0_jitter = slope_data[slope_data.columns[22:24]].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_jitter, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "    \n",
    "    group_titles.append('jitter, shimmer, pauses')\n",
    "    columns = slope_data.columns[22:24].to_list() + slope_data.columns[17:20].to_list()\n",
    "    X0_jitter = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_jitter, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('mfccs + jitter, shimmer')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[22:24].to_list()\n",
    "    X0_jitter = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_jitter, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "    \n",
    "    group_titles.append('mfccs + jitter shimmer + pauses')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[22:24].to_list() + slope_data.columns[17:20].to_list()\n",
    "    X0_jitter = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_jitter, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append(\"all bio\")\n",
    "    X0_eda = slope_data[slope_data.columns[23:30]].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_eda, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('bio + mfcc')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[23:30].to_list()\n",
    "    X0_bio_mfcc = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_bio_mfcc, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "    \n",
<<<<<<< HEAD
    "    #group_titles.append('all of em')\n",
    "    #columns = slope_data.columns[2:14].to_list() + slope_data.columns[23:30].to_list() + slope_data.columns[22:24].to_list() + slope_data.columns[17:20].to_list() + columns_demo\n",
    "    #X0 = slope_data[columns].to_numpy(copy=True)\n",
    "    #c, p = get_combo_predictions(X0, slope_data)\n",
    "    #group_c.append(c)\n",
    "    #group_p.append(p)\n",
    "    \n",
    "    group_titles.append('mfcc1-12')\n",
    "    X0_mfcc = slope_data[slope_data.columns[2:14]].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_mfcc, slope_data)\n",
=======
    "    group_titles.append('all of em')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[23:30].to_list() + slope_data.columns[22:24].to_list() + slope_data.columns[17:20].to_list() + slope_data.columns[37:44].to_list()\n",
    "    X0 = slope_data[columns].to_numpy(copy=True)\n",
    "    c, p = get_combo_predictions(X0, slope_data)\n",
>>>>>>> parent of b00050f... work since last week
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "    \n",
    "    return group_c, group_p, group_titles\n",
    "\n",
<<<<<<< HEAD
    "\n",
    "def generate_combos_with_demos(slope_data, demo_col):\n",
=======
    "#group_c, group_p, group_titles = generate_combos(all_slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "short_y_col = [\"BFNE (19)\", \"CAI Dy (16)\", \"CAI F(18)\", \"CAI PS(17)\", \"CAI Sm(15)\", \"STAI T(17)\", \"CAI St(19)\", \"STAI St(18)\"]\n",
    "correlations = np.matrix(group_c)\n",
    "pvalues = np.matrix(group_p)\n",
    "\n",
    "correlations = np.round(correlations, decimals=2)\n",
    "pvalues = np.round(pvalues, decimals=2)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,85))\n",
    "\n",
    "p = ax.matshow(correlations)\n",
    "fig.colorbar(p, ax=ax, fraction=0.05, pad=0.04)\n",
    "ax.set_xticklabels(labels=[''] + short_y_col)\n",
    "ax.set_yticklabels(labels=group_titles)\n",
    "plt.yticks(np.arange(0, len(group_titles), 1.0))\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(30)  \n",
    "    \n",
    "for i in range(len(short_y_col)):\n",
    "    for j in range(len(group_titles)):\n",
    "        text = ax.text(i, j, correlations[j, i], ha=\"center\", va=\"center\", color=\"w\")\n",
    "    \n",
    "plt.title('LinReg Correlations')\n",
    "fig.tight_layout()\n",
    "plt.savefig(DATA_PATH + 'correlatons.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(nrows=1, ncols=1, figsize=(20,85))\n",
    "p = ax2.matshow(pvalues)\n",
    "fig.colorbar(p, ax=ax2, fraction=0.05, pad=0.04)\n",
    "ax2.set_xticklabels(labels=[''] + short_y_col)  \n",
    "ax2.set_yticklabels(labels=group_titles)\n",
    "plt.yticks(np.arange(0, len(group_titles), 1.0))\n",
    "for tick in ax2.get_xticklabels():\n",
    "    tick.set_rotation(30)\n",
    "    \n",
    "for i in range(len(short_y_col)):\n",
    "    for j in range(len(group_titles)):\n",
    "        text = ax2.text(i, j, pvalues[j, i], ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "plt.title('LinReg Pvalues')\n",
    "fig.tight_layout()\n",
    "plt.savefig(DATA_PATH + 'pvalues.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#slopes_3 = get_slopes(all_data, 1, 3)\\n#c3, p3, titles3 = generate_combos(slopes_3)\\n#generate_graphs(c3, p3, titles3, '3')\\n\\n#slopes_3 = get_slopes(all_data, 5)\\n#c3, p3, titles3 = generate_combos(slopes_3)\\n#generate_graphs(c3, p3, titles3, '5')\\n\\nslopes_all = get_slopes(all_data, 1, 8)\\nc, p, titles = generate_combos(slopes_all)\\ngenerate_graphs(c, p, titles, 'all')\\n\\nfirst_4 = get_slopes(all_data, 1, 4)\\nc4, p4, titles4 = generate_combos(first_4)\\ngenerate_graphs(c4, p4, titles4, 'first4')\\n\\nmiddle_4 = get_slopes(all_data, 3, 6)\\nc4, p4, titles4 = generate_combos(middle_4)\\ngenerate_graphs(c4, p4, titles4, 'middle4')\\n\\nlast_4 = get_slopes(all_data, 5, 8)\\nc4, p4, titles4 = generate_combos(last_4)\\ngenerate_graphs(c4, p4, titles4, 'last4')\\n\\nfor i in range(1, 5):\\n    title = str(2*i - 1) + '-' + str(2*i)\\n    pair = get_slopes(all_data, 2*i - 1, 2*i)\\n    c2, p2, titles2 = generate_combos(pair)\\n    generate_graphs(c2, p2, titles2, title)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def generate_graphs(c, p, titles, specifier):\n",
    "    short_y_col = [\"BFNE (19)\", \"CAI St(19)\", \"CAI F(18)\" , \"STAI St(18)\", \"CAI PS(17)\", \"STAI T(17)\", \"CAI Dy (16)\", \"CAI Sm(15)\"]\n",
    "    correlations = np.matrix(c)\n",
    "    pvalues = np.matrix(p)\n",
    "\n",
    "    correlations = np.round(correlations, decimals=2)\n",
    "    pvalues = np.round(pvalues, decimals=2)\n",
    "    \n",
    "    data = [correlations, pvalues]\n",
    "    graph_titles = [\"correlations_\" + specifier + \".png\", \"pvalues_\" + specifier + \".png\"]\n",
    "    \n",
    "    for k in range(2):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,85))\n",
    "        \n",
    "        if k == 0:\n",
    "            p = ax.pcolor(data[k], vmin=-0.5, vmax=0.8)\n",
    "        else:\n",
    "            p = ax.pcolor(data[k], vmin = 0.0, vmax = 1.0)\n",
    "        #p = ax.matshow(data[k])\n",
    "        fig.colorbar(p, ax=ax, fraction=0.05, pad=0.04)\n",
    "        ax.set_xticklabels(labels=short_y_col)\n",
    "        ax.set_yticklabels(labels=titles)\n",
    "        plt.yticks(np.arange(0, len(titles), 1.0))\n",
    "        for tick in ax.get_xticklabels():\n",
    "            tick.set_rotation(30)  \n",
    "\n",
    "        for i in range(len(short_y_col)):\n",
    "            for j in range(len(titles)):\n",
    "                text = ax.text(i + 0.5, j + 0.5, data[k][j, i], ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(DATA_PATH + graph_titles[k])\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "\"\"\"#slopes_3 = get_slopes(all_data, 1, 3)\n",
    "#c3, p3, titles3 = generate_combos(slopes_3)\n",
    "#generate_graphs(c3, p3, titles3, '3')\n",
    "\n",
    "#slopes_3 = get_slopes(all_data, 5)\n",
    "#c3, p3, titles3 = generate_combos(slopes_3)\n",
    "#generate_graphs(c3, p3, titles3, '5')\n",
    "\n",
    "slopes_all = get_slopes(all_data, 1, 8)\n",
    "c, p, titles = generate_combos(slopes_all)\n",
    "generate_graphs(c, p, titles, 'all')\n",
    "\n",
    "first_4 = get_slopes(all_data, 1, 4)\n",
    "c4, p4, titles4 = generate_combos(first_4)\n",
    "generate_graphs(c4, p4, titles4, 'first4')\n",
    "\n",
    "middle_4 = get_slopes(all_data, 3, 6)\n",
    "c4, p4, titles4 = generate_combos(middle_4)\n",
    "generate_graphs(c4, p4, titles4, 'middle4')\n",
    "\n",
    "last_4 = get_slopes(all_data, 5, 8)\n",
    "c4, p4, titles4 = generate_combos(last_4)\n",
    "generate_graphs(c4, p4, titles4, 'last4')\n",
    "\n",
    "for i in range(1, 5):\n",
    "    title = str(2*i - 1) + '-' + str(2*i)\n",
    "    pair = get_slopes(all_data, 2*i - 1, 2*i)\n",
    "    c2, p2, titles2 = generate_combos(pair)\n",
    "    generate_graphs(c2, p2, titles2, title)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished age1\n",
      "Finished gender1\n",
      "Finished gender2\n",
      "Finished college1\n",
      "Finished college3\n",
      "Finished ethnicity1\n",
      "Finished ethnicity2\n",
      "Finished presentation1\n",
      "Finished edu1\n"
     ]
    }
   ],
   "source": [
    "def analyze_by_demo(slopes):\n",
    "    slopes.dropna(inplace=True)\n",
    "    age1 = slopes[slopes.Age == 1.0]\n",
    "    age2 = slopes[slopes.Age == 2.0]\n",
    "    age3 = slopes[slopes.Age == 3.0]\n",
    "    gender1 = slopes[slopes.Gender == 1.0]\n",
    "    gender2 = slopes[slopes.Gender == 2.0]\n",
    "    college1 = slopes[slopes.college == 1.0]\n",
    "    college2 = slopes[slopes.college == 2.0]\n",
    "    college3 = slopes[slopes.college == 3.0]\n",
    "    college4 = slopes[slopes.college == 4.0]\n",
    "    ethnicity1 = slopes[slopes.ethnicity == 1.0]\n",
    "    ethnicity2 = slopes[slopes.ethnicity == 2.0]\n",
    "    ethnicity3 = slopes[slopes.ethnicity == 3.0]\n",
    "    ethnicity4 = slopes[slopes.ethnicity == 4.0]\n",
    "    presentation0 = slopes[slopes.presentation_3_months == 0.0]\n",
    "    presentation1 = slopes[slopes.presentation_3_months == 1.0]\n",
    "    presentation2 = slopes[slopes.presentation_3_months == 2.0]\n",
    "    edu1 = slopes[slopes.highest_education == 1.0]\n",
    "    edu2 = slopes[slopes.highest_education == 2.0]\n",
    "    edu3 = slopes[slopes.highest_education == 2.0]\n",
    "    \n",
    "    all_demos = [age1, age2, age3, gender1, gender2, college1, \n",
    "                 college2, college3, college4, ethnicity1, \n",
    "                 ethnicity2, ethnicity3, ethnicity4, presentation0,\n",
    "                presentation1, presentation2, edu1, edu2, edu3]\n",
    "    demo_titles = [\"age1\", \"age2\", \"age3\", \"gender1\", \"gender2\", \"college1\", \"college2\", \n",
    "                   \"college3\", \"college4\", \"ethnicity1\", \"ethnicity2\", \"ethnicity3\", \n",
    "                   \"ethnicity4\", \"presentation0\", \"presentation1\", \"presentation2\", \"edu1\", \n",
    "                   \"edu2\", \"edu3\"]\n",
    "    \n",
    "    for d, t in zip(all_demos, demo_titles):\n",
    "        if d.shape[0] < 3:\n",
    "            continue\n",
    "        print(t, \"had\", d.shape[0], \"samples\")\n",
    "        c, p, titles = generate_combos(d)\n",
    "        print(\"Finished\", t)\n",
    "        generate_graphs(c, p, titles, t)\n",
    "        \n",
    "analyze_by_demo(all_slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combos_with_demo(slope_data, demo_col):\n",
>>>>>>> parent of b00050f... work since last week
    "    group_c = []\n",
    "    group_p = []\n",
    "    group_titles = []\n",
    "\n",
    "    group_titles.append('mfcc1-12')\n",
    "    columns = slope_data.columns[2:14].to_list() + [demo_col]\n",
    "    X0_mfcc = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_mfcc, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('pauses')\n",
    "    columns = slope_data.columns[17:20].to_list() + [demo_col]\n",
    "    X0_pauses = slope_data[columns].to_numpy(copy=True) # #pause, pause_frequency, pause_interval\n",
    "    c, p = get_combo_predictions(X0_pauses, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('mfccs + pauses')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[17:20].to_list() + [demo_col]\n",
    "    X0_pauses = slope_data[columns].to_numpy(copy=True) # #pause, pause_frequency, pause_interval\n",
    "    c, p = get_combo_predictions(X0_pauses, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('jitter, shimmer')\n",
    "    columns = slope_data.columns[22:24].to_list() + [demo_col]\n",
    "    X0_jitter = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_jitter, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "    \n",
    "    group_titles.append('jitter, shimmer, pauses')\n",
    "    columns = slope_data.columns[22:24].to_list() + slope_data.columns[17:20].to_list() + [demo_col]\n",
    "    X0_jitter = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_jitter, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('mfccs + jitter, shimmer')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[22:24].to_list() + [demo_col]\n",
    "    X0_jitter = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_jitter, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "    \n",
    "    group_titles.append('mfccs + jitter shimmer + pauses')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[22:24].to_list() + slope_data.columns[17:20].to_list() + [demo_col]\n",
    "    X0_jitter = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_jitter, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append(\"all bio\")\n",
    "    columns = slope_data.columns[23:30].to_list() + [demo_col]\n",
    "    X0_eda = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_eda, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "\n",
    "    group_titles.append('bio + mfcc')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[23:30].to_list() + [demo_col]\n",
    "    X0_bio_mfcc = slope_data[columns].to_numpy(copy=True)\n",
    "    c,p = get_combo_predictions(X0_bio_mfcc, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)\n",
    "    \n",
    "    group_titles.append('all of em')\n",
    "    columns = slope_data.columns[2:14].to_list() + slope_data.columns[23:30].to_list() + slope_data.columns[22:24].to_list() + slope_data.columns[17:20].to_list() + [demo_col]\n",
    "    X0 = slope_data[columns].to_numpy(copy=True)\n",
    "    c, p = get_combo_predictions(X0, slope_data)\n",
    "    group_c.append(c)\n",
    "    group_p.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def generate_graphs(c, p, titles, specifier):\n",
    "    short_y_col = [\"CAI St(19)\", \"CAI F(18)\" , \"STAI T(17)\"]\n",
    "    correlations = np.matrix(c)\n",
    "    pvalues = np.matrix(p)\n",
    "\n",
    "    correlations = np.round(correlations, decimals=2)\n",
    "    pvalues = np.round(pvalues, decimals=2)\n",
    "    \n",
    "    data = [correlations, pvalues]\n",
    "    graph_titles = [\"correlations_\" + specifier + \".png\", \"pvalues_\" + specifier + \".png\"]\n",
    "    \n",
    "    for k in range(2):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,85))\n",
    "        \n",
    "        if k == 0:\n",
    "            p = ax.pcolor(data[k], vmin=-0.5, vmax=0.8)\n",
    "        else:\n",
    "            p = ax.pcolor(data[k], vmin = 0.0, vmax = 1.0)\n",
    "        #p = ax.matshow(data[k])\n",
    "        fig.colorbar(p, ax=ax, fraction=0.05, pad=0.04)\n",
    "        ax.set_xticklabels(labels=short_y_col)\n",
    "        ax.set_yticklabels(labels=titles)\n",
    "        plt.yticks(np.arange(0, len(titles), 1.0))\n",
    "        for tick in ax.get_xticklabels():\n",
    "            tick.set_rotation(30)  \n",
    "\n",
    "        for i in range(len(short_y_col)):\n",
    "            for j in range(len(titles)):\n",
    "                text = ax.text(i + 0.5, j + 0.5, data[k][j, i], ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(DATA_PATH + 'slimmed/' + graph_titles[k])\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the new slimmed graphs\n",
    "#c, p, titles = generate_combos(all_slopes)\n",
    "#generate_graphs(c, p, titles, \"general\")\n",
    "\n",
    "slopes12 = get_slopes(all_data, 1, 2)\n",
    "slopes13 = get_slopes(all_data, 1, 3)\n",
    "slopes14 = get_slopes(all_data, 1, 4)\n",
    "slopes15 = get_slopes(all_data, 1, 5)\n",
    "slopes16 = get_slopes(all_data, 1, 6)\n",
    "slopes17 = get_slopes(all_data, 1, 7)\n",
    "\n",
    "slopes48 = get_slopes(all_data, 4, 8)\n",
    "slopes68 = get_slopes(all_data, 6, 8)\n",
    "slopes23 = get_slopes(all_data, 2, 3)\n",
    "\n",
    "\"\"\"c, p, titles = generate_combos(slopes12)\n",
    "generate_graphs(c, p, titles, \"upto2\")\n",
    "c, p, titles = generate_combos(slopes13)\n",
    "generate_graphs(c, p, titles, \"upto3\")\n",
    "c, p, titles = generate_combos(slopes14)\n",
    "generate_graphs(c, p, titles, \"upto4\")\"\"\"\n",
    "c, p, titles = generate_combos(slopes15)\n",
    "generate_graphs(c, p, titles, \"upto5\")\n",
    "c, p, titles = generate_combos(slopes16)\n",
    "generate_graphs(c, p, titles, \"upto6\")\n",
    "c, p, titles = generate_combos(slopes17)\n",
    "generate_graphs(c, p, titles, \"upto7\")\n",
    "\n",
    "c, p, titles = generate_combos(slopes48)\n",
    "generate_graphs(c, p, titles, \"4-8\")\n",
    "c, p, titles = generate_combos(slopes68)\n",
    "generate_graphs(c, p, titles, \"6-8\")\n",
    "c, p, titles = generate_combos(slopes23)\n",
    "generate_graphs(c, p, titles, \"2-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, titles = generate_combos(all_slopes)\n",
    "generate_graphs(c, p, titles, \"new-general1\")"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> parent of b00050f... work since last week
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
